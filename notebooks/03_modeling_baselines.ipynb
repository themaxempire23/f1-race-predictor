{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "448b5e02-fb3b-4a4a-a786-a440d1f65fdc",
   "metadata": {},
   "source": [
    "## Load features, select columns, prep targets\n",
    "\n",
    "- Goal: load enriched data and select a minimal, stable feature set.\n",
    "- We’ll start small with interpretable features and fill small gaps with medians.\n",
    "- Targets: finish_pos (regression) and top10 (classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "407e1464-37cb-4d44-8c61-caa40bc6acf3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c:\\\\Users\\\\maxnd\\\\Documents\\\\Machine Learning\\\\f1-race-predictor\\\\data\\\\processed\\\\season_2025_features_enriched.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m ROOT = Path.cwd().parent \u001b[38;5;28;01mif\u001b[39;00m Path.cwd().name == \u001b[33m\"\u001b[39m\u001b[33mnotebooks\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m Path.cwd()\n\u001b[32m      5\u001b[39m PROCESSED = ROOT / \u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m / \u001b[33m\"\u001b[39m\u001b[33mprocessed\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPROCESSED\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseason_2025_features_enriched.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mgrid_drop\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df.columns \u001b[38;5;129;01mand\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mgrid_pos\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mqual_pos\u001b[39m\u001b[33m\"\u001b[39m}.issubset(df.columns):\n\u001b[32m      9\u001b[39m     df[\u001b[33m\"\u001b[39m\u001b[33mgrid_drop\u001b[39m\u001b[33m\"\u001b[39m] = df[\u001b[33m\"\u001b[39m\u001b[33mgrid_pos\u001b[39m\u001b[33m\"\u001b[39m] - df[\u001b[33m\"\u001b[39m\u001b[33mqual_pos\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maxnd\\Documents\\Machine Learning\\f1-race-predictor\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maxnd\\Documents\\Machine Learning\\f1-race-predictor\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maxnd\\Documents\\Machine Learning\\f1-race-predictor\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maxnd\\Documents\\Machine Learning\\f1-race-predictor\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maxnd\\Documents\\Machine Learning\\f1-race-predictor\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'c:\\\\Users\\\\maxnd\\\\Documents\\\\Machine Learning\\\\f1-race-predictor\\\\data\\\\processed\\\\season_2025_features_enriched.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "PROCESSED = ROOT / \"data\" / \"processed\"\n",
    "df = pd.read_csv(PROCESSED / \"season_2025_features_enriched.csv\")\n",
    "\n",
    "if \"grid_drop\" not in df.columns and {\"grid_pos\",\"qual_pos\"}.issubset(df.columns):\n",
    "    df[\"grid_drop\"] = df[\"grid_pos\"] - df[\"qual_pos\"]\n",
    "\n",
    "features = [c for c in [\n",
    "    \"fp_mean_all_s\",\"fp_median_longrun_s\",\"fp_total_laps\",\n",
    "    \"qual_pos\",\"delta_to_pole_s\",\"grid_pos\",\"grid_drop\",\n",
    "    \"roll3_avg_pos\",\"roll5_avg_pos\",\"roll3_pts\",\"roll5_pts\",\"roll5_dnf_rate\",\n",
    "    \"team_roll3_pts\",\"team_roll5_pts\",\"track_hist_avg_pos\",\n",
    "] if c in df.columns]\n",
    "\n",
    "X = df[features].fillna(df[features].median(numeric_only=True))\n",
    "y_reg = df[\"finish_pos\"].astype(float)\n",
    "y_cls = df[\"top10\"].astype(int)\n",
    "groups = df[\"group_key\"]\n",
    "print(\"Features:\", features)\n",
    "print(\"Rows:\", X.shape[0], \"| groups:\", groups.nunique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e907cc81-a9b1-4a5d-b1ad-9ebda924b81d",
   "metadata": {},
   "source": [
    "## Diagnose missing & constant features\n",
    "\n",
    "- Goal: see where the NaNs/∞ and constants are before modeling.\n",
    "- This shows which columns have missing values and which are constant (no variance).\n",
    "- Constant or all-NaN columns don’t help models and can break scalers/imputers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc187126-68ba-4f52-9af4-cb29f162d3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top NaN counts:\n",
      " track_hist_avg_pos     200\n",
      "fp_median_longrun_s      0\n",
      "fp_mean_all_s            0\n",
      "qual_pos                 0\n",
      "delta_to_pole_s          0\n",
      "grid_pos                 0\n",
      "fp_total_laps            0\n",
      "grid_drop                0\n",
      "roll3_avg_pos            0\n",
      "roll3_pts                0\n",
      "dtype: int64\n",
      "Constant columns: ['roll5_dnf_rate', 'track_hist_avg_pos'] … total: 2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "nan_counts = X.isna().sum().sort_values(ascending=False)\n",
    "const_cols = [c for c in X.columns if X[c].nunique(dropna=True) <= 1]\n",
    "print(\"Top NaN counts:\\n\", nan_counts.head(10))\n",
    "print(\"Constant columns:\", const_cols[:10], \"… total:\", len(const_cols))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130b62dc-7b56-429b-bfcd-6d030c924d17",
   "metadata": {},
   "source": [
    "## Cleaning X: drop all-NaN & constant cols, replace ±∞\n",
    "\n",
    "- Goal: make features model-friendly; keep column list for later.\n",
    "- We safely remove unusable columns so the imputer/scaler has real data to work with.\n",
    "- We keep the final feature list to use for training and any coefficient peek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3327a942-0ee3-4481-9464-166fc0a89349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping all-NaN columns: ['track_hist_avg_pos']\n",
      "Dropping constant columns: ['roll5_dnf_rate']\n",
      "Kept 13 features.\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "Xc = X.replace([np.inf, -np.inf], np.nan).copy()\n",
    "\n",
    "# Drop columns that are entirely NaN\n",
    "all_nan_cols = Xc.columns[Xc.isna().all()]\n",
    "if len(all_nan_cols):\n",
    "    print(\"Dropping all-NaN columns:\", list(all_nan_cols))\n",
    "    Xc = Xc.drop(columns=list(all_nan_cols))\n",
    "\n",
    "# Drop columns that are constant (no variance)\n",
    "const_cols = [c for c in Xc.columns if Xc[c].nunique(dropna=True) <= 1]\n",
    "if len(const_cols):\n",
    "    print(\"Dropping constant columns:\", const_cols)\n",
    "    Xc = Xc.drop(columns=const_cols)\n",
    "\n",
    "features_clean = Xc.columns.tolist()\n",
    "print(\"Kept\", len(features_clean), \"features.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927dc89f-33d2-4c2e-853f-10aa940eb95e",
   "metadata": {},
   "source": [
    "## GroupKFold baselines\n",
    "\n",
    "- Goal: add SimpleImputer(median) so Linear/Logistic can handle missing values.\n",
    "- SimpleImputer(median) resolves the NaN error; the scaler handles different scales.\n",
    "- We print concise metrics for both tasks using GroupKFold (no weekend leakage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cd4c9f-8d40-49c3-b18a-03cdea2bfddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression — MAE: 2.28 | Spearman: -0.071\n",
      "Classification — Acc: 0.86 | F1: 0.86 | Brier: 0.099\n"
     ]
    }
   ],
   "source": [
    "# Goal: add SimpleImputer(median) so Linear/Logistic can handle missing values.\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score, f1_score\n",
    "\n",
    "def spearman_like(y_true, y_pred):\n",
    "    a = pd.Series(y_true).rank()\n",
    "    b = pd.Series(y_pred).rank()\n",
    "    return a.corr(b)\n",
    "\n",
    "gkf = GroupKFold(n_splits=min(5, groups.nunique()))\n",
    "mae, spr, acc, f1, brier = [], [], [], [], []\n",
    "\n",
    "for tr, te in gkf.split(Xc, y_reg, groups):\n",
    "    Xtr, Xte = Xc.iloc[tr], Xc.iloc[te]\n",
    "    ytr_r, yte_r = y_reg.iloc[tr], y_reg.iloc[te]\n",
    "    ytr_c, yte_c = y_cls.iloc[tr], y_cls.iloc[te]\n",
    "\n",
    "    # Regression (imputer + scaler + linear reg)\n",
    "    reg = make_pipeline(SimpleImputer(strategy=\"median\"),\n",
    "                        StandardScaler(with_mean=False),\n",
    "                        LinearRegression())\n",
    "    reg.fit(Xtr, ytr_r)\n",
    "    pred_r = reg.predict(Xte)\n",
    "    mae.append(mean_absolute_error(yte_r, pred_r))\n",
    "    spr.append(spearman_like(yte_r, pred_r))\n",
    "\n",
    "    # Classification (imputer + scaler + logistic)\n",
    "    clf = make_pipeline(SimpleImputer(strategy=\"median\"),\n",
    "                        StandardScaler(with_mean=False),\n",
    "                        LogisticRegression(max_iter=1000, solver=\"liblinear\"))\n",
    "    clf.fit(Xtr, ytr_c)\n",
    "    proba = clf.predict_proba(Xte)[:, 1]\n",
    "    pred_c = (proba >= 0.5).astype(int)\n",
    "    acc.append(accuracy_score(yte_c, pred_c))\n",
    "    f1.append(f1_score(yte_c, pred_c))\n",
    "    brier.append(np.mean((proba - yte_c.values)**2))\n",
    "\n",
    "print(f\"Regression — MAE: {np.mean(mae):.2f} | Spearman: {np.mean(spr):.3f}\")\n",
    "print(f\"Classification — Acc: {np.mean(acc):.2f} | F1: {np.mean(f1):.2f} | Brier: {np.mean(brier):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2deebd-08b2-4ae1-bf6a-291e15aa91f5",
   "metadata": {},
   "source": [
    "## Refit on all data & view coefficients\n",
    "\n",
    "- Goal: fit one final regression on all rows and inspect coefficients\n",
    "- This gives a rough sense of which features move predicted finishing position.\n",
    "- We’ll add tree-based importances in the “stronger models” step next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0fba8c-f957-4a6a-bf20-a23b5c2de664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top +ve:\n",
      " qual_pos          0.573772\n",
      "roll5_pts         0.680658\n",
      "team_roll5_pts    1.029664\n",
      "roll5_avg_pos     1.330264\n",
      "roll3_avg_pos     3.138200\n",
      "dtype: float64 \n",
      "\n",
      "Top -ve:\n",
      " team_roll3_pts   -1.180159\n",
      "roll3_pts        -0.232500\n",
      "fp_mean_all_s    -0.161033\n",
      "grid_drop        -0.148764\n",
      "fp_total_laps    -0.000673\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "final_reg = make_pipeline(SimpleImputer(strategy=\"median\"),\n",
    "                          StandardScaler(with_mean=False),\n",
    "                          LinearRegression())\n",
    "final_reg.fit(Xc, y_reg)\n",
    "\n",
    "coefs = pd.Series(final_reg.named_steps[\"linearregression\"].coef_, index=features_clean).sort_values()\n",
    "print(\"Top +ve:\\n\", coefs.tail(5), \"\\n\\nTop -ve:\\n\", coefs.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e5f296-fb39-4711-850e-344f9cfe126a",
   "metadata": {},
   "source": [
    "## RandomForest (regression) with small param sweep + GroupKFold\n",
    "\n",
    "- Goal: try a tiny RF regressor grid with GroupKFold and pick the best by MAE.\n",
    "- We evaluate a tiny RF grid with GroupKFold and choose the params that minimize MAE.\n",
    "- Spearman checks ranking quality; we keep the best config for final fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d97307-4fd7-49b2-b986-25426313537d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF-Reg {'n_estimators': 300, 'max_depth': None, 'min_samples_leaf': 1} → MAE: 2.34 | Spearman: -0.108\n",
      "RF-Reg {'n_estimators': 300, 'max_depth': 12, 'min_samples_leaf': 2} → MAE: 2.33 | Spearman: -0.102\n",
      "RF-Reg {'n_estimators': 500, 'max_depth': 16, 'min_samples_leaf': 2} → MAE: 2.31 | Spearman: -0.114\n",
      "Best RF-Reg: {'n_estimators': 500, 'max_depth': 16, 'min_samples_leaf': 2} | MAE: 2.31 | Spearman: -0.114\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "param_grid = [\n",
    "    {\"n_estimators\": 300, \"max_depth\": None, \"min_samples_leaf\": 1},\n",
    "    {\"n_estimators\": 300, \"max_depth\": 12,   \"min_samples_leaf\": 2},\n",
    "    {\"n_estimators\": 500, \"max_depth\": 16,   \"min_samples_leaf\": 2},\n",
    "]\n",
    "\n",
    "gkf = GroupKFold(n_splits=min(5, groups.nunique()))\n",
    "best, best_mae, best_spr = None, 1e9, None\n",
    "\n",
    "def spearman_like(y_true, y_pred):\n",
    "    a, b = pd.Series(y_true).rank(), pd.Series(y_pred).rank()\n",
    "    return a.corr(b)\n",
    "\n",
    "for p in param_grid:\n",
    "    maes, sprs = [], []\n",
    "    for tr, te in gkf.split(Xc, y_reg, groups):\n",
    "        imputer = SimpleImputer(strategy=\"median\")\n",
    "        Xtr, Xte = imputer.fit_transform(Xc.iloc[tr]), imputer.transform(Xc.iloc[te])\n",
    "        ytr, yte = y_reg.iloc[tr], y_reg.iloc[te]\n",
    "        rf = RandomForestRegressor(random_state=42, n_jobs=-1, **p)\n",
    "        rf.fit(Xtr, ytr)\n",
    "        pred = rf.predict(Xte)\n",
    "        maes.append(mean_absolute_error(yte, pred))\n",
    "        sprs.append(spearman_like(yte, pred))\n",
    "    m_mae, m_spr = float(np.mean(maes)), float(np.mean(sprs))\n",
    "    print(\"RF-Reg\", p, \"→ MAE:\", f\"{m_mae:.2f}\", \"| Spearman:\", f\"{m_spr:.3f}\")\n",
    "    if m_mae < best_mae:\n",
    "        best, best_mae, best_spr = p, m_mae, m_spr\n",
    "\n",
    "print(\"Best RF-Reg:\", best, \"| MAE:\", f\"{best_mae:.2f}\", \"| Spearman:\", f\"{best_spr:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f942859e-599b-4361-8afd-da336760085d",
   "metadata": {},
   "source": [
    "## RandomForest (classification) + GroupKFold (Acc/F1/Brier)\n",
    "\n",
    "- Goal: tiny RF classifier grid with GroupKFold, pick best by Brier (prob quality).\n",
    "- We select the classifier by lowest Brier (best-calibrated probabilities), and report Acc/F1 too.\n",
    "This gives us a stronger points-probability model for simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343039d4-65a4-4864-a568-9f802d1ca0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF-Cls {'n_estimators': 300, 'max_depth': None, 'min_samples_leaf': 1} → Acc: 0.84 | F1: 0.84 | Brier: 0.114\n",
      "RF-Cls {'n_estimators': 300, 'max_depth': 10, 'min_samples_leaf': 2} → Acc: 0.83 | F1: 0.83 | Brier: 0.111\n",
      "RF-Cls {'n_estimators': 500, 'max_depth': 14, 'min_samples_leaf': 2} → Acc: 0.83 | F1: 0.83 | Brier: 0.111\n",
      "Best RF-Cls: {'n_estimators': 500, 'max_depth': 14, 'min_samples_leaf': 2} | Acc: 0.83 | F1: 0.83 | Brier: 0.111\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "param_grid_cls = [\n",
    "    {\"n_estimators\": 300, \"max_depth\": None, \"min_samples_leaf\": 1},\n",
    "    {\"n_estimators\": 300, \"max_depth\": 10,   \"min_samples_leaf\": 2},\n",
    "    {\"n_estimators\": 500, \"max_depth\": 14,   \"min_samples_leaf\": 2},\n",
    "]\n",
    "\n",
    "gkf = GroupKFold(n_splits=min(5, groups.nunique()))\n",
    "best_c, best_brier, best_tuple = None, 1e9, None\n",
    "\n",
    "for p in param_grid_cls:\n",
    "    accs, f1s, briers = [], [], []\n",
    "    for tr, te in gkf.split(Xc, y_cls, groups):\n",
    "        imp = SimpleImputer(strategy=\"median\")\n",
    "        Xtr, Xte = imp.fit_transform(Xc.iloc[tr]), imp.transform(Xc.iloc[te])\n",
    "        ytr, yte = y_cls.iloc[tr], y_cls.iloc[te]\n",
    "        rf = RandomForestClassifier(random_state=42, n_jobs=-1, class_weight=None, **p)\n",
    "        rf.fit(Xtr, ytr)\n",
    "        proba = rf.predict_proba(Xte)[:, 1]\n",
    "        pred = (proba >= 0.5).astype(int)\n",
    "        accs.append(accuracy_score(yte, pred))\n",
    "        f1s.append(f1_score(yte, pred))\n",
    "        briers.append(np.mean((proba - yte.values)**2))\n",
    "    m_acc, m_f1, m_brier = float(np.mean(accs)), float(np.mean(f1s)), float(np.mean(briers))\n",
    "    print(\"RF-Cls\", p, \"→ Acc:\", f\"{m_acc:.2f}\", \"| F1:\", f\"{m_f1:.2f}\", \"| Brier:\", f\"{m_brier:.3f}\")\n",
    "    if m_brier < best_brier:\n",
    "        best_c, best_brier, best_tuple = p, m_brier, (m_acc, m_f1)\n",
    "\n",
    "print(\"Best RF-Cls:\", best_c, \"| Acc:\", f\"{best_tuple[0]:.2f}\", \"| F1:\", f\"{best_tuple[1]:.2f}\", \"| Brier:\", f\"{best_brier:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b4b93b-6596-4f90-891b-290903c216a3",
   "metadata": {},
   "source": [
    "## Fit best RFs on all data and save\n",
    "\n",
    "- Goal:refit best RF models on all rows and save them for reuse.\n",
    "- We train both best models on all data and save them to /models for reuse.\n",
    "- These will power the Monte Carlo simulation in the next phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13500c88-1a67-4c38-9443-7e61ddf008f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: rf_finishpos.joblib and rf_top10.joblib\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import dump\n",
    "from pathlib import Path\n",
    "\n",
    "MODELS = (Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()) / \"models\"\n",
    "MODELS.mkdir(exist_ok=True)\n",
    "\n",
    "# Refit regression\n",
    "imp_reg = SimpleImputer(strategy=\"median\")\n",
    "rf_reg  = RandomForestRegressor(random_state=42, n_jobs=-1, **best)\n",
    "reg_pipe = Pipeline([(\"imp\", imp_reg), (\"rf\", rf_reg)])\n",
    "reg_pipe.fit(Xc, y_reg)\n",
    "dump(reg_pipe, MODELS / \"rf_finishpos.joblib\")\n",
    "\n",
    "# Refit classification\n",
    "imp_cls = SimpleImputer(strategy=\"median\")\n",
    "rf_cls  = RandomForestClassifier(random_state=42, n_jobs=-1, **best_c)\n",
    "cls_pipe = Pipeline([(\"imp\", imp_cls), (\"rf\", rf_cls)])\n",
    "cls_pipe.fit(Xc, y_cls)\n",
    "dump(cls_pipe, MODELS / \"rf_top10.joblib\")\n",
    "\n",
    "print(\"Saved:\", (MODELS / 'rf_finishpos.joblib').name, \"and\", (MODELS / 'rf_top10.joblib').name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (f1-predictor)",
   "language": "python",
   "name": "f1-predictor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
