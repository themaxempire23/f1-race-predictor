{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9201060d",
   "metadata": {},
   "source": [
    "# Phase 2 — Feature Engineering (Rolling & Team Form Fix)\n",
    "\n",
    "**Goal:** Add rolling form, reliability (DNF rate), team rolling points, and track history to your season table using index-safe operations.\n",
    "\n",
    "**How to use:** Run each step **in order**. Each step has a short goal and a 2‑line explanation. When it finishes, move to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089743ab",
   "metadata": {},
   "source": [
    "## Step 0 — Load `season_df` (from memory or from `/data/processed`)\n",
    "\n",
    "**Goal:** Ensure we have `season_df` ready. If it's not defined, we load the latest `season_table_fast_robust_*.csv` (or `season_table_fast_*.csv`) from `/data/processed`.\n",
    "\n",
    "**Why:** Rolling features require a season-wide table. This step makes the notebook self-contained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c929b48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: season_table_fast_2023_k10.csv | shape: (20, 27)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd, numpy as np\n",
    "import glob\n",
    "\n",
    "# Project paths\n",
    "ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "PROCESSED = ROOT / \"data\" / \"processed\"\n",
    "PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# If season_df already exists (e.g., defined in your previous notebook), keep it.\n",
    "try:\n",
    "    _check = season_df.head(1)  # type: ignore[name-defined]\n",
    "    print(\"Using season_df from memory:\", season_df.shape)  # type: ignore[name-defined]\n",
    "except Exception:\n",
    "    # Try to load the most recent robust season table\n",
    "    candidates = sorted([*PROCESSED.glob(\"season_table_fast_robust_*_k*.csv\"),\n",
    "                         *PROCESSED.glob(\"season_table_fast_*_k*.csv\")],\n",
    "                        key=lambda p: (p.stat().st_mtime, p.name), reverse=True)\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(\"No season_table_*.csv found in /data/processed. Run the season builder first.\")\n",
    "    season_path = candidates[0]\n",
    "    season_df = pd.read_csv(season_path)\n",
    "    # Parse dates if present\n",
    "    if \"event_date\" in season_df.columns:\n",
    "        season_df[\"event_date\"] = pd.to_datetime(season_df[\"event_date\"], errors=\"coerce\")\n",
    "    print(\"Loaded:\", season_path.name, \"| shape:\", season_df.shape)\n",
    "\n",
    "# Small sanity: make sure required columns exist\n",
    "req_cols = [\"Driver\",\"TeamName\",\"finish_pos\",\"points\",\"Status\",\"event_name\",\"event_date\",\"group_key\",\"year\"]\n",
    "missing = [c for c in req_cols if c not in season_df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing columns in season_df: {missing}. Rebuild the season table with the robust builder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43065d8c",
   "metadata": {},
   "source": [
    "## Step 1 — Base copy & DNF flag\n",
    "\n",
    "**Goal:** Copy the season table, sort by driver/date, and add a conservative `dnf` flag for reliability features.\n",
    "\n",
    "**Why:** We keep the original data intact and compute a robust DNF signal for rolling stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "530a7e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 20 | Drivers: 20 | Teams: 10\n"
     ]
    }
   ],
   "source": [
    "df = season_df.copy().sort_values([\"Driver\",\"event_date\"]).reset_index(drop=True)\n",
    "\n",
    "def is_dnf_row(row):\n",
    "    status = str(row.get(\"Status\", \"\")).lower()\n",
    "    pos = row.get(\"finish_pos\", np.nan)\n",
    "    pts = row.get(\"points\", 0.0)\n",
    "    return ((\"finished\" not in status) and (\"classified\" not in status) and (pd.isna(pos) or pos > 20)) or (pd.isna(pos) and pts == 0)\n",
    "\n",
    "df[\"dnf\"] = df.apply(is_dnf_row, axis=1).astype(int)\n",
    "print(\"Rows:\", len(df), \"| Drivers:\", df['Driver'].nunique(), \"| Teams:\", df['TeamName'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8843ca3d",
   "metadata": {},
   "source": [
    "## Step 2 — Rolling form per driver (index-safe)\n",
    "\n",
    "**Goal:** Add rolling averages of finish position & points, plus rolling DNF rate using `groupby(...).transform(...)`.\n",
    "\n",
    "**Why:** `transform` keeps row alignment 1:1, avoiding index mismatches and future pandas warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d65dce6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added driver rolling features.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Driver</th>\n",
       "      <th>FP1_mean_all_s</th>\n",
       "      <th>FP1_laps</th>\n",
       "      <th>FP1_median_longrun_s</th>\n",
       "      <th>FP2_mean_all_s</th>\n",
       "      <th>FP2_laps</th>\n",
       "      <th>FP2_median_longrun_s</th>\n",
       "      <th>FP3_mean_all_s</th>\n",
       "      <th>FP3_laps</th>\n",
       "      <th>FP3_median_longrun_s</th>\n",
       "      <th>...</th>\n",
       "      <th>round</th>\n",
       "      <th>event_name</th>\n",
       "      <th>event_date</th>\n",
       "      <th>group_key</th>\n",
       "      <th>dnf</th>\n",
       "      <th>roll3_avg_pos</th>\n",
       "      <th>roll5_avg_pos</th>\n",
       "      <th>roll3_pts</th>\n",
       "      <th>roll5_pts</th>\n",
       "      <th>roll5_dnf_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALB</td>\n",
       "      <td>108.091714</td>\n",
       "      <td>7</td>\n",
       "      <td>97.024</td>\n",
       "      <td>101.704100</td>\n",
       "      <td>20</td>\n",
       "      <td>98.0580</td>\n",
       "      <td>111.5360</td>\n",
       "      <td>7</td>\n",
       "      <td>94.4850</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Bahrain Grand Prix</td>\n",
       "      <td>2023-03-05</td>\n",
       "      <td>2023_R1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALO</td>\n",
       "      <td>112.108071</td>\n",
       "      <td>14</td>\n",
       "      <td>95.879</td>\n",
       "      <td>103.729278</td>\n",
       "      <td>18</td>\n",
       "      <td>97.3835</td>\n",
       "      <td>112.2390</td>\n",
       "      <td>6</td>\n",
       "      <td>102.6665</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Bahrain Grand Prix</td>\n",
       "      <td>2023-03-05</td>\n",
       "      <td>2023_R1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOT</td>\n",
       "      <td>103.471444</td>\n",
       "      <td>9</td>\n",
       "      <td>98.325</td>\n",
       "      <td>102.306588</td>\n",
       "      <td>17</td>\n",
       "      <td>98.7330</td>\n",
       "      <td>105.9956</td>\n",
       "      <td>5</td>\n",
       "      <td>94.3560</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Bahrain Grand Prix</td>\n",
       "      <td>2023-03-05</td>\n",
       "      <td>2023_R1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Driver  FP1_mean_all_s  FP1_laps  FP1_median_longrun_s  FP2_mean_all_s  \\\n",
       "0    ALB      108.091714         7                97.024      101.704100   \n",
       "1    ALO      112.108071        14                95.879      103.729278   \n",
       "2    BOT      103.471444         9                98.325      102.306588   \n",
       "\n",
       "   FP2_laps  FP2_median_longrun_s  FP3_mean_all_s  FP3_laps  \\\n",
       "0        20               98.0580        111.5360         7   \n",
       "1        18               97.3835        112.2390         6   \n",
       "2        17               98.7330        105.9956         5   \n",
       "\n",
       "   FP3_median_longrun_s  ...  round          event_name  event_date  \\\n",
       "0               94.4850  ...      1  Bahrain Grand Prix  2023-03-05   \n",
       "1              102.6665  ...      1  Bahrain Grand Prix  2023-03-05   \n",
       "2               94.3560  ...      1  Bahrain Grand Prix  2023-03-05   \n",
       "\n",
       "   group_key dnf  roll3_avg_pos  roll5_avg_pos roll3_pts  roll5_pts  \\\n",
       "0    2023_R1   0           10.0           10.0       1.0        1.0   \n",
       "1    2023_R1   0            3.0            3.0      15.0       15.0   \n",
       "2    2023_R1   0            8.0            8.0       4.0        4.0   \n",
       "\n",
       "   roll5_dnf_rate  \n",
       "0             0.0  \n",
       "1             0.0  \n",
       "2             0.0  \n",
       "\n",
       "[3 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values([\"Driver\",\"event_date\"]).reset_index(drop=True)\n",
    "\n",
    "df[\"roll3_avg_pos\"]  = df.groupby(\"Driver\")[\"finish_pos\"].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
    "df[\"roll5_avg_pos\"]  = df.groupby(\"Driver\")[\"finish_pos\"].transform(lambda s: s.rolling(5, min_periods=1).mean())\n",
    "df[\"roll3_pts\"]      = df.groupby(\"Driver\")[\"points\"].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
    "df[\"roll5_pts\"]      = df.groupby(\"Driver\")[\"points\"].transform(lambda s: s.rolling(5, min_periods=1).mean())\n",
    "df[\"roll5_dnf_rate\"] = df.groupby(\"Driver\")[\"dnf\"].transform(  lambda s: s.rolling(5, min_periods=1).mean())\n",
    "\n",
    "print(\"Added driver rolling features.\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7aaa38",
   "metadata": {},
   "source": [
    "## Step 3 — Team rolling points (one row per team per race → merge back)\n",
    "\n",
    "**Goal:** Compute team points per race, then rolling means per team, and merge back to driver rows via `(TeamName, group_key)`.\n",
    "\n",
    "**Why:** This avoids `groupby.apply` reindex issues and ensures each driver row gets the same team signal for that race."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41a1f773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added team rolling features.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Driver</th>\n",
       "      <th>FP1_mean_all_s</th>\n",
       "      <th>FP1_laps</th>\n",
       "      <th>FP1_median_longrun_s</th>\n",
       "      <th>FP2_mean_all_s</th>\n",
       "      <th>FP2_laps</th>\n",
       "      <th>FP2_median_longrun_s</th>\n",
       "      <th>FP3_mean_all_s</th>\n",
       "      <th>FP3_laps</th>\n",
       "      <th>FP3_median_longrun_s</th>\n",
       "      <th>...</th>\n",
       "      <th>event_date</th>\n",
       "      <th>group_key</th>\n",
       "      <th>dnf</th>\n",
       "      <th>roll3_avg_pos</th>\n",
       "      <th>roll5_avg_pos</th>\n",
       "      <th>roll3_pts</th>\n",
       "      <th>roll5_pts</th>\n",
       "      <th>roll5_dnf_rate</th>\n",
       "      <th>team_roll3_pts</th>\n",
       "      <th>team_roll5_pts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALB</td>\n",
       "      <td>108.091714</td>\n",
       "      <td>7</td>\n",
       "      <td>97.024</td>\n",
       "      <td>101.704100</td>\n",
       "      <td>20</td>\n",
       "      <td>98.0580</td>\n",
       "      <td>111.5360</td>\n",
       "      <td>7</td>\n",
       "      <td>94.4850</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-03-05</td>\n",
       "      <td>2023_R1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALO</td>\n",
       "      <td>112.108071</td>\n",
       "      <td>14</td>\n",
       "      <td>95.879</td>\n",
       "      <td>103.729278</td>\n",
       "      <td>18</td>\n",
       "      <td>97.3835</td>\n",
       "      <td>112.2390</td>\n",
       "      <td>6</td>\n",
       "      <td>102.6665</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-03-05</td>\n",
       "      <td>2023_R1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOT</td>\n",
       "      <td>103.471444</td>\n",
       "      <td>9</td>\n",
       "      <td>98.325</td>\n",
       "      <td>102.306588</td>\n",
       "      <td>17</td>\n",
       "      <td>98.7330</td>\n",
       "      <td>105.9956</td>\n",
       "      <td>5</td>\n",
       "      <td>94.3560</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-03-05</td>\n",
       "      <td>2023_R1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Driver  FP1_mean_all_s  FP1_laps  FP1_median_longrun_s  FP2_mean_all_s  \\\n",
       "0    ALB      108.091714         7                97.024      101.704100   \n",
       "1    ALO      112.108071        14                95.879      103.729278   \n",
       "2    BOT      103.471444         9                98.325      102.306588   \n",
       "\n",
       "   FP2_laps  FP2_median_longrun_s  FP3_mean_all_s  FP3_laps  \\\n",
       "0        20               98.0580        111.5360         7   \n",
       "1        18               97.3835        112.2390         6   \n",
       "2        17               98.7330        105.9956         5   \n",
       "\n",
       "   FP3_median_longrun_s  ...  event_date  group_key  dnf  roll3_avg_pos  \\\n",
       "0               94.4850  ...  2023-03-05    2023_R1    0           10.0   \n",
       "1              102.6665  ...  2023-03-05    2023_R1    0            3.0   \n",
       "2               94.3560  ...  2023-03-05    2023_R1    0            8.0   \n",
       "\n",
       "  roll5_avg_pos  roll3_pts  roll5_pts roll5_dnf_rate  team_roll3_pts  \\\n",
       "0          10.0        1.0        1.0            0.0             1.0   \n",
       "1           3.0       15.0       15.0            0.0            23.0   \n",
       "2           8.0        4.0        4.0            0.0             4.0   \n",
       "\n",
       "   team_roll5_pts  \n",
       "0             1.0  \n",
       "1            23.0  \n",
       "2             4.0  \n",
       "\n",
       "[3 rows x 35 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Aggregate team points per race\n",
    "team_race = (df.groupby([\"TeamName\",\"group_key\",\"event_date\"], as_index=False)[\"points\"]\n",
    "               .sum()\n",
    "               .rename(columns={\"points\":\"team_points_race\"}))\n",
    "\n",
    "# 2) Rolling team points over time\n",
    "team_race = team_race.sort_values([\"TeamName\",\"event_date\"]).reset_index(drop=True)\n",
    "team_race[\"team_roll3_pts\"] = (team_race.groupby(\"TeamName\")[\"team_points_race\"]\n",
    "                               .transform(lambda s: s.rolling(3, min_periods=1).mean()))\n",
    "team_race[\"team_roll5_pts\"] = (team_race.groupby(\"TeamName\")[\"team_points_race\"]\n",
    "                               .transform(lambda s: s.rolling(5, min_periods=1).mean()))\n",
    "\n",
    "# 3) Merge back to driver rows\n",
    "df = df.merge(team_race[[\"TeamName\",\"group_key\",\"team_roll3_pts\",\"team_roll5_pts\"]],\n",
    "              on=[\"TeamName\",\"group_key\"], how=\"left\")\n",
    "print(\"Added team rolling features.\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc82e17",
   "metadata": {},
   "source": [
    "## Step 4 — Track history per driver at this event (leakage-safe)\n",
    "\n",
    "**Goal:** For each `(Driver, event_name)`, compute the average of **past** finishes using `shift().expanding().mean()`.\n",
    "\n",
    "**Why:** The `shift()` excludes the current race, preventing leakage; `transform` keeps perfect index alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fce9603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added track history feature.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Driver</th>\n",
       "      <th>FP1_mean_all_s</th>\n",
       "      <th>FP1_laps</th>\n",
       "      <th>FP1_median_longrun_s</th>\n",
       "      <th>FP2_mean_all_s</th>\n",
       "      <th>FP2_laps</th>\n",
       "      <th>FP2_median_longrun_s</th>\n",
       "      <th>FP3_mean_all_s</th>\n",
       "      <th>FP3_laps</th>\n",
       "      <th>FP3_median_longrun_s</th>\n",
       "      <th>...</th>\n",
       "      <th>group_key</th>\n",
       "      <th>dnf</th>\n",
       "      <th>roll3_avg_pos</th>\n",
       "      <th>roll5_avg_pos</th>\n",
       "      <th>roll3_pts</th>\n",
       "      <th>roll5_pts</th>\n",
       "      <th>roll5_dnf_rate</th>\n",
       "      <th>team_roll3_pts</th>\n",
       "      <th>team_roll5_pts</th>\n",
       "      <th>track_hist_avg_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALB</td>\n",
       "      <td>108.091714</td>\n",
       "      <td>7</td>\n",
       "      <td>97.024</td>\n",
       "      <td>101.704100</td>\n",
       "      <td>20</td>\n",
       "      <td>98.0580</td>\n",
       "      <td>111.5360</td>\n",
       "      <td>7</td>\n",
       "      <td>94.4850</td>\n",
       "      <td>...</td>\n",
       "      <td>2023_R1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALO</td>\n",
       "      <td>112.108071</td>\n",
       "      <td>14</td>\n",
       "      <td>95.879</td>\n",
       "      <td>103.729278</td>\n",
       "      <td>18</td>\n",
       "      <td>97.3835</td>\n",
       "      <td>112.2390</td>\n",
       "      <td>6</td>\n",
       "      <td>102.6665</td>\n",
       "      <td>...</td>\n",
       "      <td>2023_R1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOT</td>\n",
       "      <td>103.471444</td>\n",
       "      <td>9</td>\n",
       "      <td>98.325</td>\n",
       "      <td>102.306588</td>\n",
       "      <td>17</td>\n",
       "      <td>98.7330</td>\n",
       "      <td>105.9956</td>\n",
       "      <td>5</td>\n",
       "      <td>94.3560</td>\n",
       "      <td>...</td>\n",
       "      <td>2023_R1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Driver  FP1_mean_all_s  FP1_laps  FP1_median_longrun_s  FP2_mean_all_s  \\\n",
       "0    ALB      108.091714         7                97.024      101.704100   \n",
       "1    ALO      112.108071        14                95.879      103.729278   \n",
       "2    BOT      103.471444         9                98.325      102.306588   \n",
       "\n",
       "   FP2_laps  FP2_median_longrun_s  FP3_mean_all_s  FP3_laps  \\\n",
       "0        20               98.0580        111.5360         7   \n",
       "1        18               97.3835        112.2390         6   \n",
       "2        17               98.7330        105.9956         5   \n",
       "\n",
       "   FP3_median_longrun_s  ...  group_key  dnf  roll3_avg_pos  roll5_avg_pos  \\\n",
       "0               94.4850  ...    2023_R1    0           10.0           10.0   \n",
       "1              102.6665  ...    2023_R1    0            3.0            3.0   \n",
       "2               94.3560  ...    2023_R1    0            8.0            8.0   \n",
       "\n",
       "  roll3_pts  roll5_pts  roll5_dnf_rate team_roll3_pts  team_roll5_pts  \\\n",
       "0       1.0        1.0             0.0            1.0             1.0   \n",
       "1      15.0       15.0             0.0           23.0            23.0   \n",
       "2       4.0        4.0             0.0            4.0             4.0   \n",
       "\n",
       "   track_hist_avg_pos  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2                 NaN  \n",
       "\n",
       "[3 rows x 36 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values([\"Driver\",\"event_name\",\"event_date\"]).reset_index(drop=True)\n",
    "df[\"track_hist_avg_pos\"] = (df.groupby([\"Driver\",\"event_name\"])[\"finish_pos\"]\n",
    "                              .transform(lambda s: s.shift().expanding().mean()))\n",
    "print(\"Added track history feature.\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881ae6cb",
   "metadata": {},
   "source": [
    "## Step 5 — Save enriched season dataset\n",
    "\n",
    "**Goal:** Persist the enriched features to `/data/processed` for modeling in Phase 3.\n",
    "\n",
    "**Why:** Keeps your modeling inputs reproducible and decoupled from data assembly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e9a4a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: season_2023_features_enriched.csv | shape: (20, 36)\n"
     ]
    }
   ],
   "source": [
    "year_val = int(df[\"year\"].dropna().iloc[0]) if \"year\" in df.columns and df[\"year\"].notna().any() else 0\n",
    "out_path = PROCESSED / (f\"season_{year_val}_features_enriched.csv\" if year_val else \"season_features_enriched.csv\")\n",
    "df.to_csv(out_path, index=False)\n",
    "print(\"Saved:\", out_path.name, \"| shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fdb728-00b8-4234-8b69-82e8d76fbc20",
   "metadata": {},
   "source": [
    "## Phase 2.5 Ensuring we have multiple races"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b22916-64de-49c4-81da-b3ebbb442197",
   "metadata": {},
   "source": [
    "## Check how many races we have (groups)\n",
    "\n",
    "- Goal: verify we have enough race-weekends for CV; if not, rebuild quickly.\n",
    "- We need ≥3 race-weekends (groups) for meaningful GroupKFold.\n",
    "- If you see 1, run the next cell to build more rounds fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a7302b4-7d3c-4396-be87-979cd1f0717d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: (20, 36) | race-weekends: 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "PROCESSED = ROOT / \"data\" / \"processed\"\n",
    "\n",
    "df = pd.read_csv(PROCESSED / \"season_2023_features_enriched.csv\")\n",
    "n_groups = df[\"group_key\"].nunique()\n",
    "print(\"Rows:\", df.shape, \"| race-weekends:\", n_groups)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee97c11-d335-4732-80a2-2516f8cfc09c",
   "metadata": {},
   "source": [
    "## Building more rounds fast (K=10) and re-enrich\n",
    "- Goal: create a bigger season set quickly, then re-run the rolling notebook afterwards.\n",
    "- This builds K=10 rounds using results-only loads (fast), then re-applies rolling/team/track features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "350c6f02-4a18-4215-ac15-722eb7cce1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req         WARNING \tDEFAULT CACHE ENABLED! (3.0 GB) C:\\Users\\maxnd\\AppData\\Local\\Temp\\fastf1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built: (200, 18) | groups: 10\n",
      "Re-saved enriched: season_2023_features_enriched.csv | shape: (200, 27) | groups: 10\n"
     ]
    }
   ],
   "source": [
    "import logging, numpy as np, pandas as pd, fastf1\n",
    "from pathlib import Path\n",
    "logging.getLogger(\"fastf1\").setLevel(logging.WARNING)\n",
    "\n",
    "ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "PROCESSED = ROOT / \"data\" / \"processed\"\n",
    "\n",
    "# Reuse fast, results-only loaders (defined earlier). If you don't have them in this notebook, paste them here again.\n",
    "def load_results_fast(year:int, rnd:int, code:str):\n",
    "    s = fastf1.get_session(year, rnd, code)\n",
    "    try: s.load(laps=False, telemetry=False, weather=False, messages=False)\n",
    "    except TypeError:\n",
    "        try: s.load(telemetry=False)\n",
    "        except Exception: s.load()\n",
    "    return s\n",
    "\n",
    "def extract_quali_df(year: int, rnd: int, rres_for_map: pd.DataFrame) -> pd.DataFrame:\n",
    "    q = load_results_fast(year, rnd, \"Q\")\n",
    "    qres = q.results.copy()\n",
    "    num_to_abbr = {}\n",
    "    if {\"DriverNumber\",\"Abbreviation\"}.issubset(rres_for_map.columns):\n",
    "        num_to_abbr = dict(zip(rres_for_map[\"DriverNumber\"], rres_for_map[\"Abbreviation\"]))\n",
    "    if \"Abbreviation\" in qres.columns:\n",
    "        qres = qres.rename(columns={\"Abbreviation\": \"Driver\"})\n",
    "    elif \"DriverNumber\" in qres.columns and num_to_abbr:\n",
    "        qres[\"Driver\"] = qres[\"DriverNumber\"].map(num_to_abbr)\n",
    "    else:\n",
    "        return pd.DataFrame(columns=[\"Driver\",\"qual_pos\",\"best_qual_t\",\"delta_to_pole_s\"])\n",
    "    for c in [\"Q1\",\"Q2\",\"Q3\"]:\n",
    "        if c in qres.columns: qres[c] = pd.to_timedelta(qres[c], errors=\"coerce\")\n",
    "    qres = qres.rename(columns={\"Position\":\"qual_pos\"})\n",
    "    tcols = [c for c in [\"Q1\",\"Q2\",\"Q3\"] if c in qres.columns]\n",
    "    if tcols:\n",
    "        qres[\"best_qual_t\"] = qres[tcols].min(axis=1, skipna=True)\n",
    "        pole = qres[\"best_qual_t\"].min()\n",
    "        qres[\"delta_to_pole_s\"] = (qres[\"best_qual_t\"] - pole).dt.total_seconds()\n",
    "    else:\n",
    "        qres[\"best_qual_t\"] = pd.NaT; qres[\"delta_to_pole_s\"] = np.nan\n",
    "    return qres[[\"Driver\",\"qual_pos\",\"best_qual_t\",\"delta_to_pole_s\"]]\n",
    "\n",
    "# Light practice (uses your cached CSVs if present; otherwise returns empty safely)\n",
    "def practice_features_light(year:int, rnd:int) -> pd.DataFrame:\n",
    "    RAW = PROCESSED.parent / \"raw\"\n",
    "    def read_laps(y,r,code):\n",
    "        p = RAW / f\"laps_{y}_R{r}_{code}.csv\"\n",
    "        if not p.exists(): raise FileNotFoundError\n",
    "        df = pd.read_csv(p)\n",
    "        if \"LapTime\" in df.columns: df[\"LapTime\"] = pd.to_timedelta(df[\"LapTime\"], errors=\"coerce\")\n",
    "        return df\n",
    "    frames = []\n",
    "    for code in [\"FP1\",\"FP2\",\"FP3\"]:\n",
    "        try:\n",
    "            laps = read_laps(year, rnd, code)\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "        valid = laps.copy()\n",
    "        for col in [\"PitInLap\",\"PitOutLap\",\"IsAccurate\"]:\n",
    "            if col in valid.columns:\n",
    "                if col in [\"PitInLap\",\"PitOutLap\"]: valid = valid[~valid[col].fillna(False)]\n",
    "                else: valid = valid[valid[col].fillna(True)]\n",
    "        valid = valid[valid[\"LapTime\"].notna()]\n",
    "        if {\"Driver\",\"Stint\"}.issubset(valid.columns):\n",
    "            stint_sizes = valid.groupby([\"Driver\",\"Stint\"])[\"LapTime\"].transform(\"size\")\n",
    "            longrun = valid[stint_sizes >= 5]\n",
    "        else:\n",
    "            longrun = pd.DataFrame(columns=valid.columns)\n",
    "        grp_all = valid.groupby(\"Driver\")[\"LapTime\"]\n",
    "        grp_lr  = longrun.groupby(\"Driver\")[\"LapTime\"] if not longrun.empty else None\n",
    "        dfp = pd.DataFrame({\n",
    "            \"Driver\": grp_all.count().index,\n",
    "            f\"{code}_mean_all_s\": grp_all.mean().dt.total_seconds().values,\n",
    "            f\"{code}_laps\": grp_all.count().values,\n",
    "        })\n",
    "        med_all = grp_all.median().dt.total_seconds()\n",
    "        med_lr  = (grp_lr.median().dt.total_seconds() if grp_lr is not None else pd.Series(dtype=float))\n",
    "        dfp[f\"{code}_median_longrun_s\"] = dfp[\"Driver\"].map(med_lr).fillna(dfp[\"Driver\"].map(med_all))\n",
    "        frames.append(dfp)\n",
    "    if not frames: return pd.DataFrame(columns=[\"Driver\"])\n",
    "    out = frames[0]\n",
    "    for f in frames[1:]: out = out.merge(f, on=\"Driver\", how=\"outer\")\n",
    "    out[\"fp_mean_all_s\"]      = out[[c for c in out.columns if c.endswith(\"_mean_all_s\")]].mean(axis=1)\n",
    "    out[\"fp_median_longrun_s\"]= out[[c for c in out.columns if c.endswith(\"_median_longrun_s\")]].mean(axis=1)\n",
    "    out[\"fp_total_laps\"]      = out[[c for c in out.columns if c.endswith(\"_laps\")]].sum(axis=1).astype(int)\n",
    "    return out[[\"Driver\",\"fp_mean_all_s\",\"fp_median_longrun_s\",\"fp_total_laps\"]]\n",
    "\n",
    "def build_season_table_fast_robust(year:int, k:int=10) -> pd.DataFrame:\n",
    "    schedule = fastf1.get_event_schedule(year, include_testing=False)\n",
    "    rounds = schedule[\"RoundNumber\"].tolist()[:k]\n",
    "    rows = []\n",
    "    for rnd in rounds:\n",
    "        try:\n",
    "            r = load_results_fast(year, rnd, \"R\")\n",
    "            rraw = r.results.copy()\n",
    "            keep = [c for c in [\"Abbreviation\",\"DriverNumber\",\"TeamName\",\"GridPosition\",\"Position\",\"Points\",\"Status\"] if c in rraw.columns]\n",
    "            rres = rraw[keep].copy()\n",
    "            base = rres.rename(columns={\"Abbreviation\":\"Driver\"})\n",
    "            base[\"finish_pos\"] = pd.to_numeric(base.get(\"Position\"), errors=\"coerce\")\n",
    "            base[\"points\"]     = pd.to_numeric(base.get(\"Points\"), errors=\"coerce\").fillna(0.0)\n",
    "            base[\"top10\"]      = (base[\"points\"] > 0).astype(int)\n",
    "            grid = base[[\"Driver\",\"GridPosition\"]].rename(columns={\"GridPosition\":\"grid_pos\"}) if \"GridPosition\" in base.columns else pd.DataFrame(columns=[\"Driver\",\"grid_pos\"])\n",
    "            qres = extract_quali_df(year, rnd, rraw)\n",
    "            fp   = practice_features_light(year, rnd)\n",
    "            ev   = fastf1.get_event(year, rnd)\n",
    "            merged = (base[[\"Driver\",\"TeamName\",\"finish_pos\",\"points\",\"top10\",\"Status\"]]\n",
    "                      .merge(grid, on=\"Driver\", how=\"left\")\n",
    "                      .merge(qres, on=\"Driver\", how=\"left\")\n",
    "                      .merge(fp, on=\"Driver\", how=\"left\"))\n",
    "            merged[\"year\"], merged[\"round\"] = year, rnd\n",
    "            merged[\"event_name\"], merged[\"event_date\"] = ev[\"EventName\"], pd.to_datetime(ev[\"EventDate\"])\n",
    "            merged[\"group_key\"] = f\"{year}_R{rnd}\"\n",
    "            rows.append(merged)\n",
    "        except Exception as e:\n",
    "            print(f\"Skip {year} R{rnd}: {e.__class__.__name__}: {e}\")\n",
    "    out = pd.concat(rows, ignore_index=True) if rows else pd.DataFrame()\n",
    "    out.to_csv(PROCESSED / f\"season_table_fast_robust_{year}_k{k}.csv\", index=False)\n",
    "    return out\n",
    "\n",
    "YEAR, K = 2023, 10\n",
    "season_big = build_season_table_fast_robust(YEAR, K)\n",
    "print(\"Built:\", season_big.shape, \"| groups:\", season_big['group_key'].nunique())\n",
    "\n",
    "# Re-use your rolling steps (R0–R4) or do the short inline version:\n",
    "season_big[\"event_date\"] = pd.to_datetime(season_big[\"event_date\"], errors=\"coerce\")\n",
    "df = season_big.sort_values([\"Driver\",\"event_date\"]).reset_index(drop=True)\n",
    "\n",
    "def is_dnf_row(row):\n",
    "    st = str(row.get(\"Status\",\"\")).lower()\n",
    "    pos = row.get(\"finish_pos\"); pts = row.get(\"points\",0.0)\n",
    "    return ((\"finished\" not in st) and (\"classified\" not in st) and (pd.isna(pos) or pos>20)) or (pd.isna(pos) and pts==0)\n",
    "\n",
    "df[\"dnf\"] = df.apply(is_dnf_row, axis=1).astype(int)\n",
    "df[\"roll3_avg_pos\"]  = df.groupby(\"Driver\")[\"finish_pos\"].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
    "df[\"roll5_avg_pos\"]  = df.groupby(\"Driver\")[\"finish_pos\"].transform(lambda s: s.rolling(5, min_periods=1).mean())\n",
    "df[\"roll3_pts\"]      = df.groupby(\"Driver\")[\"points\"].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
    "df[\"roll5_pts\"]      = df.groupby(\"Driver\")[\"points\"].transform(lambda s: s.rolling(5, min_periods=1).mean())\n",
    "df[\"roll5_dnf_rate\"] = df.groupby(\"Driver\")[\"dnf\"].transform(  lambda s: s.rolling(5, min_periods=1).mean())\n",
    "\n",
    "team_race = (df.groupby([\"TeamName\",\"group_key\",\"event_date\"], as_index=False)[\"points\"].sum()\n",
    "               .rename(columns={\"points\":\"team_points_race\"}))\n",
    "team_race = team_race.sort_values([\"TeamName\",\"event_date\"]).reset_index(drop=True)\n",
    "team_race[\"team_roll3_pts\"] = team_race.groupby(\"TeamName\")[\"team_points_race\"].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
    "team_race[\"team_roll5_pts\"] = team_race.groupby(\"TeamName\")[\"team_points_race\"].transform(lambda s: s.rolling(5, min_periods=1).mean())\n",
    "df = df.merge(team_race[[\"TeamName\",\"group_key\",\"team_roll3_pts\",\"team_roll5_pts\"]], on=[\"TeamName\",\"group_key\"], how=\"left\")\n",
    "\n",
    "df = df.sort_values([\"Driver\",\"event_name\",\"event_date\"]).reset_index(drop=True)\n",
    "df[\"track_hist_avg_pos\"] = df.groupby([\"Driver\",\"event_name\"])[\"finish_pos\"].transform(lambda s: s.shift().expanding().mean())\n",
    "\n",
    "out = PROCESSED / \"season_2023_features_enriched.csv\"\n",
    "df.to_csv(out, index=False)\n",
    "print(\"Re-saved enriched:\", out.name, \"| shape:\", df.shape, \"| groups:\", df['group_key'].nunique())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (f1-predictor)",
   "language": "python",
   "name": "f1-predictor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
