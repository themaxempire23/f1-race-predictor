{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9201060d",
   "metadata": {},
   "source": [
    "# Phase 2 — Feature Engineering (Rolling & Team Form Fix)\n",
    "\n",
    "**Goal:** Add rolling form, reliability (DNF rate), team rolling points, and track history to your season table using index-safe operations.\n",
    "\n",
    "**How to use:** Run each step **in order**. Each step has a short goal and a 2‑line explanation. When it finishes, move to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089743ab",
   "metadata": {},
   "source": [
    "## Step 0 — Load `season_df` (from memory or from `/data/processed`)\n",
    "\n",
    "**Goal:** Ensure we have `season_df` ready. If it's not defined, we load the latest `season_table_fast_robust_*.csv` (or `season_table_fast_*.csv`) from `/data/processed`.\n",
    "\n",
    "**Why:** Rolling features require a season-wide table. This step makes the notebook self-contained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c929b48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: season_table_fast_robust_2023_k10.csv | shape: (200, 18)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd, numpy as np\n",
    "import glob\n",
    "\n",
    "# Project paths\n",
    "ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "PROCESSED = ROOT / \"data\" / \"processed\"\n",
    "PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# If season_df already exists (e.g., defined in your previous notebook), keep it.\n",
    "try:\n",
    "    _check = season_df.head(1)  # type: ignore[name-defined]\n",
    "    print(\"Using season_df from memory:\", season_df.shape)  # type: ignore[name-defined]\n",
    "except Exception:\n",
    "    # Try to load the most recent robust season table\n",
    "    candidates = sorted([*PROCESSED.glob(\"season_table_fast_robust_*_k*.csv\"),\n",
    "                         *PROCESSED.glob(\"season_table_fast_*_k*.csv\")],\n",
    "                        key=lambda p: (p.stat().st_mtime, p.name), reverse=True)\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(\"No season_table_*.csv found in /data/processed. Run the season builder first.\")\n",
    "    season_path = candidates[0]\n",
    "    season_df = pd.read_csv(season_path)\n",
    "    # Parse dates if present\n",
    "    if \"event_date\" in season_df.columns:\n",
    "        season_df[\"event_date\"] = pd.to_datetime(season_df[\"event_date\"], errors=\"coerce\")\n",
    "    print(\"Loaded:\", season_path.name, \"| shape:\", season_df.shape)\n",
    "\n",
    "# Small sanity: make sure required columns exist\n",
    "req_cols = [\"Driver\",\"TeamName\",\"finish_pos\",\"points\",\"Status\",\"event_name\",\"event_date\",\"group_key\",\"year\"]\n",
    "missing = [c for c in req_cols if c not in season_df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing columns in season_df: {missing}. Rebuild the season table with the robust builder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43065d8c",
   "metadata": {},
   "source": [
    "## Step 1 — Base copy & DNF flag\n",
    "\n",
    "**Goal:** Copy the season table, sort by driver/date, and add a conservative `dnf` flag for reliability features.\n",
    "\n",
    "**Why:** We keep the original data intact and compute a robust DNF signal for rolling stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "530a7e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 200 | Drivers: 20 | Teams: 10\n"
     ]
    }
   ],
   "source": [
    "df = season_df.copy().sort_values([\"Driver\",\"event_date\"]).reset_index(drop=True)\n",
    "\n",
    "def is_dnf_row(row):\n",
    "    status = str(row.get(\"Status\", \"\")).lower()\n",
    "    pos = row.get(\"finish_pos\", np.nan)\n",
    "    pts = row.get(\"points\", 0.0)\n",
    "    return ((\"finished\" not in status) and (\"classified\" not in status) and (pd.isna(pos) or pos > 20)) or (pd.isna(pos) and pts == 0)\n",
    "\n",
    "df[\"dnf\"] = df.apply(is_dnf_row, axis=1).astype(int)\n",
    "print(\"Rows:\", len(df), \"| Drivers:\", df['Driver'].nunique(), \"| Teams:\", df['TeamName'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8843ca3d",
   "metadata": {},
   "source": [
    "## Step 2 — Rolling form per driver (index-safe)\n",
    "\n",
    "**Goal:** Add rolling averages of finish position & points, plus rolling DNF rate using `groupby(...).transform(...)`.\n",
    "\n",
    "**Why:** `transform` keeps row alignment 1:1, avoiding index mismatches and future pandas warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d65dce6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added driver rolling features.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Driver</th>\n",
       "      <th>TeamName</th>\n",
       "      <th>finish_pos</th>\n",
       "      <th>points</th>\n",
       "      <th>top10</th>\n",
       "      <th>Status</th>\n",
       "      <th>grid_pos</th>\n",
       "      <th>qual_pos</th>\n",
       "      <th>best_qual_t</th>\n",
       "      <th>delta_to_pole_s</th>\n",
       "      <th>...</th>\n",
       "      <th>round</th>\n",
       "      <th>event_name</th>\n",
       "      <th>event_date</th>\n",
       "      <th>group_key</th>\n",
       "      <th>dnf</th>\n",
       "      <th>roll3_avg_pos</th>\n",
       "      <th>roll5_avg_pos</th>\n",
       "      <th>roll3_pts</th>\n",
       "      <th>roll5_pts</th>\n",
       "      <th>roll5_dnf_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALB</td>\n",
       "      <td>Williams</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Finished</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0 days 00:01:31.461000</td>\n",
       "      <td>1.753</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Bahrain Grand Prix</td>\n",
       "      <td>2023-03-05</td>\n",
       "      <td>2023_R1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALB</td>\n",
       "      <td>Williams</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Retired</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0 days 00:01:29.994000</td>\n",
       "      <td>1.729</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Saudi Arabian Grand Prix</td>\n",
       "      <td>2023-03-19</td>\n",
       "      <td>2023_R2</td>\n",
       "      <td>0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALB</td>\n",
       "      <td>Williams</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Retired</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0 days 00:01:17.609000</td>\n",
       "      <td>0.877</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>2023-04-02</td>\n",
       "      <td>2023_R3</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Driver  TeamName  finish_pos  points  top10    Status  grid_pos  qual_pos  \\\n",
       "0    ALB  Williams        10.0     1.0      1  Finished      15.0      15.0   \n",
       "1    ALB  Williams        19.0     0.0      0   Retired      17.0      17.0   \n",
       "2    ALB  Williams        19.0     0.0      0   Retired       8.0       8.0   \n",
       "\n",
       "              best_qual_t  delta_to_pole_s  ...  round  \\\n",
       "0  0 days 00:01:31.461000            1.753  ...      1   \n",
       "1  0 days 00:01:29.994000            1.729  ...      2   \n",
       "2  0 days 00:01:17.609000            0.877  ...      3   \n",
       "\n",
       "                 event_name  event_date  group_key  dnf roll3_avg_pos  \\\n",
       "0        Bahrain Grand Prix  2023-03-05    2023_R1    0          10.0   \n",
       "1  Saudi Arabian Grand Prix  2023-03-19    2023_R2    0          14.5   \n",
       "2     Australian Grand Prix  2023-04-02    2023_R3    0          16.0   \n",
       "\n",
       "  roll5_avg_pos roll3_pts  roll5_pts  roll5_dnf_rate  \n",
       "0          10.0  1.000000   1.000000             0.0  \n",
       "1          14.5  0.500000   0.500000             0.0  \n",
       "2          16.0  0.333333   0.333333             0.0  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values([\"Driver\",\"event_date\"]).reset_index(drop=True)\n",
    "\n",
    "df[\"roll3_avg_pos\"]  = df.groupby(\"Driver\")[\"finish_pos\"].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
    "df[\"roll5_avg_pos\"]  = df.groupby(\"Driver\")[\"finish_pos\"].transform(lambda s: s.rolling(5, min_periods=1).mean())\n",
    "df[\"roll3_pts\"]      = df.groupby(\"Driver\")[\"points\"].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
    "df[\"roll5_pts\"]      = df.groupby(\"Driver\")[\"points\"].transform(lambda s: s.rolling(5, min_periods=1).mean())\n",
    "df[\"roll5_dnf_rate\"] = df.groupby(\"Driver\")[\"dnf\"].transform(  lambda s: s.rolling(5, min_periods=1).mean())\n",
    "\n",
    "print(\"Added driver rolling features.\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7aaa38",
   "metadata": {},
   "source": [
    "## Step 3 — Team rolling points (one row per team per race → merge back)\n",
    "\n",
    "**Goal:** Compute team points per race, then rolling means per team, and merge back to driver rows via `(TeamName, group_key)`.\n",
    "\n",
    "**Why:** This avoids `groupby.apply` reindex issues and ensures each driver row gets the same team signal for that race."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41a1f773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added team rolling features.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Driver</th>\n",
       "      <th>TeamName</th>\n",
       "      <th>finish_pos</th>\n",
       "      <th>points</th>\n",
       "      <th>top10</th>\n",
       "      <th>Status</th>\n",
       "      <th>grid_pos</th>\n",
       "      <th>qual_pos</th>\n",
       "      <th>best_qual_t</th>\n",
       "      <th>delta_to_pole_s</th>\n",
       "      <th>...</th>\n",
       "      <th>event_date</th>\n",
       "      <th>group_key</th>\n",
       "      <th>dnf</th>\n",
       "      <th>roll3_avg_pos</th>\n",
       "      <th>roll5_avg_pos</th>\n",
       "      <th>roll3_pts</th>\n",
       "      <th>roll5_pts</th>\n",
       "      <th>roll5_dnf_rate</th>\n",
       "      <th>team_roll3_pts</th>\n",
       "      <th>team_roll5_pts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALB</td>\n",
       "      <td>Williams</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Finished</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0 days 00:01:31.461000</td>\n",
       "      <td>1.753</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-03-05</td>\n",
       "      <td>2023_R1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALB</td>\n",
       "      <td>Williams</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Retired</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0 days 00:01:29.994000</td>\n",
       "      <td>1.729</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-03-19</td>\n",
       "      <td>2023_R2</td>\n",
       "      <td>0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALB</td>\n",
       "      <td>Williams</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Retired</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0 days 00:01:17.609000</td>\n",
       "      <td>0.877</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-04-02</td>\n",
       "      <td>2023_R3</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Driver  TeamName  finish_pos  points  top10    Status  grid_pos  qual_pos  \\\n",
       "0    ALB  Williams        10.0     1.0      1  Finished      15.0      15.0   \n",
       "1    ALB  Williams        19.0     0.0      0   Retired      17.0      17.0   \n",
       "2    ALB  Williams        19.0     0.0      0   Retired       8.0       8.0   \n",
       "\n",
       "              best_qual_t  delta_to_pole_s  ...  event_date  group_key  dnf  \\\n",
       "0  0 days 00:01:31.461000            1.753  ...  2023-03-05    2023_R1    0   \n",
       "1  0 days 00:01:29.994000            1.729  ...  2023-03-19    2023_R2    0   \n",
       "2  0 days 00:01:17.609000            0.877  ...  2023-04-02    2023_R3    0   \n",
       "\n",
       "   roll3_avg_pos  roll5_avg_pos roll3_pts roll5_pts roll5_dnf_rate  \\\n",
       "0           10.0           10.0  1.000000  1.000000            0.0   \n",
       "1           14.5           14.5  0.500000  0.500000            0.0   \n",
       "2           16.0           16.0  0.333333  0.333333            0.0   \n",
       "\n",
       "   team_roll3_pts  team_roll5_pts  \n",
       "0        1.000000        1.000000  \n",
       "1        0.500000        0.500000  \n",
       "2        0.333333        0.333333  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Aggregate team points per race\n",
    "team_race = (df.groupby([\"TeamName\",\"group_key\",\"event_date\"], as_index=False)[\"points\"]\n",
    "               .sum()\n",
    "               .rename(columns={\"points\":\"team_points_race\"}))\n",
    "\n",
    "# 2) Rolling team points over time\n",
    "team_race = team_race.sort_values([\"TeamName\",\"event_date\"]).reset_index(drop=True)\n",
    "team_race[\"team_roll3_pts\"] = (team_race.groupby(\"TeamName\")[\"team_points_race\"]\n",
    "                               .transform(lambda s: s.rolling(3, min_periods=1).mean()))\n",
    "team_race[\"team_roll5_pts\"] = (team_race.groupby(\"TeamName\")[\"team_points_race\"]\n",
    "                               .transform(lambda s: s.rolling(5, min_periods=1).mean()))\n",
    "\n",
    "# 3) Merge back to driver rows\n",
    "df = df.merge(team_race[[\"TeamName\",\"group_key\",\"team_roll3_pts\",\"team_roll5_pts\"]],\n",
    "              on=[\"TeamName\",\"group_key\"], how=\"left\")\n",
    "print(\"Added team rolling features.\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc82e17",
   "metadata": {},
   "source": [
    "## Step 4 — Track history per driver at this event (leakage-safe)\n",
    "\n",
    "**Goal:** For each `(Driver, event_name)`, compute the average of **past** finishes using `shift().expanding().mean()`.\n",
    "\n",
    "**Why:** The `shift()` excludes the current race, preventing leakage; `transform` keeps perfect index alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fce9603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added track history feature.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Driver</th>\n",
       "      <th>TeamName</th>\n",
       "      <th>finish_pos</th>\n",
       "      <th>points</th>\n",
       "      <th>top10</th>\n",
       "      <th>Status</th>\n",
       "      <th>grid_pos</th>\n",
       "      <th>qual_pos</th>\n",
       "      <th>best_qual_t</th>\n",
       "      <th>delta_to_pole_s</th>\n",
       "      <th>...</th>\n",
       "      <th>group_key</th>\n",
       "      <th>dnf</th>\n",
       "      <th>roll3_avg_pos</th>\n",
       "      <th>roll5_avg_pos</th>\n",
       "      <th>roll3_pts</th>\n",
       "      <th>roll5_pts</th>\n",
       "      <th>roll5_dnf_rate</th>\n",
       "      <th>team_roll3_pts</th>\n",
       "      <th>team_roll5_pts</th>\n",
       "      <th>track_hist_avg_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALB</td>\n",
       "      <td>Williams</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Retired</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0 days 00:01:17.609000</td>\n",
       "      <td>0.877</td>\n",
       "      <td>...</td>\n",
       "      <td>2023_R3</td>\n",
       "      <td>0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALB</td>\n",
       "      <td>Williams</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Finished</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0 days 00:01:05.387000</td>\n",
       "      <td>0.996</td>\n",
       "      <td>...</td>\n",
       "      <td>2023_R9</td>\n",
       "      <td>0</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>12.4</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALB</td>\n",
       "      <td>Williams</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Finished</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0 days 00:01:41.818000</td>\n",
       "      <td>1.615</td>\n",
       "      <td>...</td>\n",
       "      <td>2023_R4</td>\n",
       "      <td>0</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Driver  TeamName  finish_pos  points  top10    Status  grid_pos  qual_pos  \\\n",
       "0    ALB  Williams        19.0     0.0      0   Retired       8.0       8.0   \n",
       "1    ALB  Williams        11.0     0.0      0  Finished      10.0      10.0   \n",
       "2    ALB  Williams        12.0     0.0      0  Finished      12.0      13.0   \n",
       "\n",
       "              best_qual_t  delta_to_pole_s  ...  group_key  dnf  \\\n",
       "0  0 days 00:01:17.609000            0.877  ...    2023_R3    0   \n",
       "1  0 days 00:01:05.387000            0.996  ...    2023_R9    0   \n",
       "2  0 days 00:01:41.818000            1.615  ...    2023_R4    0   \n",
       "\n",
       "   roll3_avg_pos  roll5_avg_pos  roll3_pts roll5_pts roll5_dnf_rate  \\\n",
       "0      16.000000           16.0   0.333333  0.333333            0.0   \n",
       "1      11.333333           12.4   2.000000  1.200000            0.0   \n",
       "2      16.666667           15.0   0.000000  0.250000            0.0   \n",
       "\n",
       "  team_roll3_pts  team_roll5_pts  track_hist_avg_pos  \n",
       "0       0.333333        0.333333                 NaN  \n",
       "1       2.000000        1.200000                 NaN  \n",
       "2       0.000000        0.250000                 NaN  \n",
       "\n",
       "[3 rows x 27 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values([\"Driver\",\"event_name\",\"event_date\"]).reset_index(drop=True)\n",
    "df[\"track_hist_avg_pos\"] = (df.groupby([\"Driver\",\"event_name\"])[\"finish_pos\"]\n",
    "                              .transform(lambda s: s.shift().expanding().mean()))\n",
    "print(\"Added track history feature.\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881ae6cb",
   "metadata": {},
   "source": [
    "## Step 5 — Save enriched season dataset\n",
    "\n",
    "**Goal:** Persist the enriched features to `/data/processed` for modeling in Phase 3.\n",
    "\n",
    "**Why:** Keeps your modeling inputs reproducible and decoupled from data assembly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e9a4a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: season_2023_features_enriched.csv | shape: (200, 27)\n"
     ]
    }
   ],
   "source": [
    "year_val = int(df[\"year\"].dropna().iloc[0]) if \"year\" in df.columns and df[\"year\"].notna().any() else 0\n",
    "out_path = PROCESSED / (f\"season_{year_val}_features_enriched.csv\" if year_val else \"season_features_enriched.csv\")\n",
    "df.to_csv(out_path, index=False)\n",
    "print(\"Saved:\", out_path.name, \"| shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fdb728-00b8-4234-8b69-82e8d76fbc20",
   "metadata": {},
   "source": [
    "## Phase 2.5 Ensuring we have multiple races"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b22916-64de-49c4-81da-b3ebbb442197",
   "metadata": {},
   "source": [
    "## Check how many races we have (groups)\n",
    "\n",
    "- Goal: verify we have enough race-weekends for CV; if not, rebuild quickly.\n",
    "- We need ≥3 race-weekends (groups) for meaningful GroupKFold.\n",
    "- If you see 1, run the next cell to build more rounds fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a7302b4-7d3c-4396-be87-979cd1f0717d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c:\\\\Users\\\\maxnd\\\\Documents\\\\Machine Learning\\\\f1-race-predictor\\\\data\\\\processed\\\\season_2025_features_enriched.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m ROOT = Path.cwd().parent \u001b[38;5;28;01mif\u001b[39;00m Path.cwd().name == \u001b[33m\"\u001b[39m\u001b[33mnotebooks\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m Path.cwd()\n\u001b[32m      5\u001b[39m PROCESSED = ROOT / \u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m / \u001b[33m\"\u001b[39m\u001b[33mprocessed\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPROCESSED\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseason_2025_features_enriched.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m n_groups = df[\u001b[33m\"\u001b[39m\u001b[33mgroup_key\u001b[39m\u001b[33m\"\u001b[39m].nunique()\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRows:\u001b[39m\u001b[33m\"\u001b[39m, df.shape, \u001b[33m\"\u001b[39m\u001b[33m| race-weekends:\u001b[39m\u001b[33m\"\u001b[39m, n_groups)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maxnd\\Documents\\Machine Learning\\f1-race-predictor\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maxnd\\Documents\\Machine Learning\\f1-race-predictor\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maxnd\\Documents\\Machine Learning\\f1-race-predictor\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maxnd\\Documents\\Machine Learning\\f1-race-predictor\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maxnd\\Documents\\Machine Learning\\f1-race-predictor\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'c:\\\\Users\\\\maxnd\\\\Documents\\\\Machine Learning\\\\f1-race-predictor\\\\data\\\\processed\\\\season_2025_features_enriched.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "PROCESSED = ROOT / \"data\" / \"processed\"\n",
    "\n",
    "df = pd.read_csv(PROCESSED / \"season_2025_features_enriched.csv\")\n",
    "n_groups = df[\"group_key\"].nunique()\n",
    "print(\"Rows:\", df.shape, \"| race-weekends:\", n_groups)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee97c11-d335-4732-80a2-2516f8cfc09c",
   "metadata": {},
   "source": [
    "## Building more rounds fast (K=10) and re-enrich\n",
    "- Goal: create a bigger season set quickly, then re-run the rolling notebook afterwards.\n",
    "- This builds K=10 rounds using results-only loads (fast), then re-applies rolling/team/track features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350c6f02-4a18-4215-ac15-722eb7cce1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req         WARNING \tDEFAULT CACHE ENABLED! (3.0 GB) C:\\Users\\maxnd\\AppData\\Local\\Temp\\fastf1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built: (200, 18) | groups: 10\n",
      "Re-saved enriched: season_2023_features_enriched.csv | shape: (200, 27) | groups: 10\n"
     ]
    }
   ],
   "source": [
    "import logging, numpy as np, pandas as pd, fastf1\n",
    "from pathlib import Path\n",
    "logging.getLogger(\"fastf1\").setLevel(logging.WARNING)\n",
    "\n",
    "ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "PROCESSED = ROOT / \"data\" / \"processed\"\n",
    "\n",
    "# Reuse fast, results-only loaders (defined earlier). If you don't have them in this notebook, paste them here again.\n",
    "def load_results_fast(year:int, rnd:int, code:str):\n",
    "    s = fastf1.get_session(year, rnd, code)\n",
    "    try: s.load(laps=False, telemetry=False, weather=False, messages=False)\n",
    "    except TypeError:\n",
    "        try: s.load(telemetry=False)\n",
    "        except Exception: s.load()\n",
    "    return s\n",
    "\n",
    "def extract_quali_df(year: int, rnd: int, rres_for_map: pd.DataFrame) -> pd.DataFrame:\n",
    "    q = load_results_fast(year, rnd, \"Q\")\n",
    "    qres = q.results.copy()\n",
    "    num_to_abbr = {}\n",
    "    if {\"DriverNumber\",\"Abbreviation\"}.issubset(rres_for_map.columns):\n",
    "        num_to_abbr = dict(zip(rres_for_map[\"DriverNumber\"], rres_for_map[\"Abbreviation\"]))\n",
    "    if \"Abbreviation\" in qres.columns:\n",
    "        qres = qres.rename(columns={\"Abbreviation\": \"Driver\"})\n",
    "    elif \"DriverNumber\" in qres.columns and num_to_abbr:\n",
    "        qres[\"Driver\"] = qres[\"DriverNumber\"].map(num_to_abbr)\n",
    "    else:\n",
    "        return pd.DataFrame(columns=[\"Driver\",\"qual_pos\",\"best_qual_t\",\"delta_to_pole_s\"])\n",
    "    for c in [\"Q1\",\"Q2\",\"Q3\"]:\n",
    "        if c in qres.columns: qres[c] = pd.to_timedelta(qres[c], errors=\"coerce\")\n",
    "    qres = qres.rename(columns={\"Position\":\"qual_pos\"})\n",
    "    tcols = [c for c in [\"Q1\",\"Q2\",\"Q3\"] if c in qres.columns]\n",
    "    if tcols:\n",
    "        qres[\"best_qual_t\"] = qres[tcols].min(axis=1, skipna=True)\n",
    "        pole = qres[\"best_qual_t\"].min()\n",
    "        qres[\"delta_to_pole_s\"] = (qres[\"best_qual_t\"] - pole).dt.total_seconds()\n",
    "    else:\n",
    "        qres[\"best_qual_t\"] = pd.NaT; qres[\"delta_to_pole_s\"] = np.nan\n",
    "    return qres[[\"Driver\",\"qual_pos\",\"best_qual_t\",\"delta_to_pole_s\"]]\n",
    "\n",
    "# Light practice (uses your cached CSVs if present; otherwise returns empty safely)\n",
    "def practice_features_light(year:int, rnd:int) -> pd.DataFrame:\n",
    "    RAW = PROCESSED.parent / \"raw\"\n",
    "    def read_laps(y,r,code):\n",
    "        p = RAW / f\"laps_{y}_R{r}_{code}.csv\"\n",
    "        if not p.exists(): raise FileNotFoundError\n",
    "        df = pd.read_csv(p)\n",
    "        if \"LapTime\" in df.columns: df[\"LapTime\"] = pd.to_timedelta(df[\"LapTime\"], errors=\"coerce\")\n",
    "        return df\n",
    "    frames = []\n",
    "    for code in [\"FP1\",\"FP2\",\"FP3\"]:\n",
    "        try:\n",
    "            laps = read_laps(year, rnd, code)\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "        valid = laps.copy()\n",
    "        for col in [\"PitInLap\",\"PitOutLap\",\"IsAccurate\"]:\n",
    "            if col in valid.columns:\n",
    "                if col in [\"PitInLap\",\"PitOutLap\"]: valid = valid[~valid[col].fillna(False)]\n",
    "                else: valid = valid[valid[col].fillna(True)]\n",
    "        valid = valid[valid[\"LapTime\"].notna()]\n",
    "        if {\"Driver\",\"Stint\"}.issubset(valid.columns):\n",
    "            stint_sizes = valid.groupby([\"Driver\",\"Stint\"])[\"LapTime\"].transform(\"size\")\n",
    "            longrun = valid[stint_sizes >= 5]\n",
    "        else:\n",
    "            longrun = pd.DataFrame(columns=valid.columns)\n",
    "        grp_all = valid.groupby(\"Driver\")[\"LapTime\"]\n",
    "        grp_lr  = longrun.groupby(\"Driver\")[\"LapTime\"] if not longrun.empty else None\n",
    "        dfp = pd.DataFrame({\n",
    "            \"Driver\": grp_all.count().index,\n",
    "            f\"{code}_mean_all_s\": grp_all.mean().dt.total_seconds().values,\n",
    "            f\"{code}_laps\": grp_all.count().values,\n",
    "        })\n",
    "        med_all = grp_all.median().dt.total_seconds()\n",
    "        med_lr  = (grp_lr.median().dt.total_seconds() if grp_lr is not None else pd.Series(dtype=float))\n",
    "        dfp[f\"{code}_median_longrun_s\"] = dfp[\"Driver\"].map(med_lr).fillna(dfp[\"Driver\"].map(med_all))\n",
    "        frames.append(dfp)\n",
    "    if not frames: return pd.DataFrame(columns=[\"Driver\"])\n",
    "    out = frames[0]\n",
    "    for f in frames[1:]: out = out.merge(f, on=\"Driver\", how=\"outer\")\n",
    "    out[\"fp_mean_all_s\"]      = out[[c for c in out.columns if c.endswith(\"_mean_all_s\")]].mean(axis=1)\n",
    "    out[\"fp_median_longrun_s\"]= out[[c for c in out.columns if c.endswith(\"_median_longrun_s\")]].mean(axis=1)\n",
    "    out[\"fp_total_laps\"]      = out[[c for c in out.columns if c.endswith(\"_laps\")]].sum(axis=1).astype(int)\n",
    "    return out[[\"Driver\",\"fp_mean_all_s\",\"fp_median_longrun_s\",\"fp_total_laps\"]]\n",
    "\n",
    "def build_season_table_fast_robust(year:int, k:int=10) -> pd.DataFrame:\n",
    "    schedule = fastf1.get_event_schedule(year, include_testing=False)\n",
    "    rounds = schedule[\"RoundNumber\"].tolist()[:k]\n",
    "    rows = []\n",
    "    for rnd in rounds:\n",
    "        try:\n",
    "            r = load_results_fast(year, rnd, \"R\")\n",
    "            rraw = r.results.copy()\n",
    "            keep = [c for c in [\"Abbreviation\",\"DriverNumber\",\"TeamName\",\"GridPosition\",\"Position\",\"Points\",\"Status\"] if c in rraw.columns]\n",
    "            rres = rraw[keep].copy()\n",
    "            base = rres.rename(columns={\"Abbreviation\":\"Driver\"})\n",
    "            base[\"finish_pos\"] = pd.to_numeric(base.get(\"Position\"), errors=\"coerce\")\n",
    "            base[\"points\"]     = pd.to_numeric(base.get(\"Points\"), errors=\"coerce\").fillna(0.0)\n",
    "            base[\"top10\"]      = (base[\"points\"] > 0).astype(int)\n",
    "            grid = base[[\"Driver\",\"GridPosition\"]].rename(columns={\"GridPosition\":\"grid_pos\"}) if \"GridPosition\" in base.columns else pd.DataFrame(columns=[\"Driver\",\"grid_pos\"])\n",
    "            qres = extract_quali_df(year, rnd, rraw)\n",
    "            fp   = practice_features_light(year, rnd)\n",
    "            ev   = fastf1.get_event(year, rnd)\n",
    "            merged = (base[[\"Driver\",\"TeamName\",\"finish_pos\",\"points\",\"top10\",\"Status\"]]\n",
    "                      .merge(grid, on=\"Driver\", how=\"left\")\n",
    "                      .merge(qres, on=\"Driver\", how=\"left\")\n",
    "                      .merge(fp, on=\"Driver\", how=\"left\"))\n",
    "            merged[\"year\"], merged[\"round\"] = year, rnd\n",
    "            merged[\"event_name\"], merged[\"event_date\"] = ev[\"EventName\"], pd.to_datetime(ev[\"EventDate\"])\n",
    "            merged[\"group_key\"] = f\"{year}_R{rnd}\"\n",
    "            rows.append(merged)\n",
    "        except Exception as e:\n",
    "            print(f\"Skip {year} R{rnd}: {e.__class__.__name__}: {e}\")\n",
    "    out = pd.concat(rows, ignore_index=True) if rows else pd.DataFrame()\n",
    "    out.to_csv(PROCESSED / f\"season_table_fast_robust_{year}_k{k}.csv\", index=False)\n",
    "    return out\n",
    "\n",
    "YEAR, K = 2025, 10\n",
    "season_big = build_season_table_fast_robust(YEAR, K)\n",
    "print(\"Built:\", season_big.shape, \"| groups:\", season_big['group_key'].nunique())\n",
    "\n",
    "# Re-use your rolling steps (R0–R4) or do the short inline version:\n",
    "season_big[\"event_date\"] = pd.to_datetime(season_big[\"event_date\"], errors=\"coerce\")\n",
    "df = season_big.sort_values([\"Driver\",\"event_date\"]).reset_index(drop=True)\n",
    "\n",
    "def is_dnf_row(row):\n",
    "    st = str(row.get(\"Status\",\"\")).lower()\n",
    "    pos = row.get(\"finish_pos\"); pts = row.get(\"points\",0.0)\n",
    "    return ((\"finished\" not in st) and (\"classified\" not in st) and (pd.isna(pos) or pos>20)) or (pd.isna(pos) and pts==0)\n",
    "\n",
    "df[\"dnf\"] = df.apply(is_dnf_row, axis=1).astype(int)\n",
    "df[\"roll3_avg_pos\"]  = df.groupby(\"Driver\")[\"finish_pos\"].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
    "df[\"roll5_avg_pos\"]  = df.groupby(\"Driver\")[\"finish_pos\"].transform(lambda s: s.rolling(5, min_periods=1).mean())\n",
    "df[\"roll3_pts\"]      = df.groupby(\"Driver\")[\"points\"].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
    "df[\"roll5_pts\"]      = df.groupby(\"Driver\")[\"points\"].transform(lambda s: s.rolling(5, min_periods=1).mean())\n",
    "df[\"roll5_dnf_rate\"] = df.groupby(\"Driver\")[\"dnf\"].transform(  lambda s: s.rolling(5, min_periods=1).mean())\n",
    "\n",
    "team_race = (df.groupby([\"TeamName\",\"group_key\",\"event_date\"], as_index=False)[\"points\"].sum()\n",
    "               .rename(columns={\"points\":\"team_points_race\"}))\n",
    "team_race = team_race.sort_values([\"TeamName\",\"event_date\"]).reset_index(drop=True)\n",
    "team_race[\"team_roll3_pts\"] = team_race.groupby(\"TeamName\")[\"team_points_race\"].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
    "team_race[\"team_roll5_pts\"] = team_race.groupby(\"TeamName\")[\"team_points_race\"].transform(lambda s: s.rolling(5, min_periods=1).mean())\n",
    "df = df.merge(team_race[[\"TeamName\",\"group_key\",\"team_roll3_pts\",\"team_roll5_pts\"]], on=[\"TeamName\",\"group_key\"], how=\"left\")\n",
    "\n",
    "df = df.sort_values([\"Driver\",\"event_name\",\"event_date\"]).reset_index(drop=True)\n",
    "df[\"track_hist_avg_pos\"] = df.groupby([\"Driver\",\"event_name\"])[\"finish_pos\"].transform(lambda s: s.shift().expanding().mean())\n",
    "\n",
    "out = PROCESSED / \"season_2025_features_enriched.csv\"\n",
    "df.to_csv(out, index=False)\n",
    "print(\"Re-saved enriched:\", out.name, \"| shape:\", df.shape, \"| groups:\", df['group_key'].nunique())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (f1-predictor)",
   "language": "python",
   "name": "f1-predictor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
